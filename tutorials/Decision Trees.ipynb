{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees are useful and powerful algorithms for classifying and regressing data. It works on recursive partitioning which will be shown algorithmically in this notebook. Though most of the the time, Sci-Kit Learn can be used to implement this machine learning method simply, it is useful to take a look at the inner workings of these algorithms. This notebook will first introduce a decision tree from scratch. It will then show an example using SK Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree From Scratch Using HMEQ Data\n",
    "\n",
    "Firstly, we will go through a decision tree made from scratch. The following code is based on the material originally created by Sebastian Mantey for the Iris Dataset whose GitHub is here: https://github.com/SebastianMantey/Decision-Tree-from-Scratch. You can also search his video on YouTube. The code has been adapted to this course's format and fit to HMEQ Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Relevant Libraries & Data\n",
    "\n",
    "The first decision tree will be coded from scratch using only pandas and NumPy. There are faster ways to do this using Sci-Kit Learn which is a l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://github.com/Humboldt-WI/bads/blob/master/data/hmeq_modeling.csv?raw=true'\n",
    "df = pd.read_csv(filename, header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "      <th>DEROGzero</th>\n",
       "      <th>REASON_HomeImp</th>\n",
       "      <th>REASON_IsMissing</th>\n",
       "      <th>JOB_Office</th>\n",
       "      <th>JOB_Other</th>\n",
       "      <th>JOB_ProfExe</th>\n",
       "      <th>JOB_Sales</th>\n",
       "      <th>JOB_Self</th>\n",
       "      <th>DELINQcat_1</th>\n",
       "      <th>DELINQcat_1+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.832283</td>\n",
       "      <td>-1.295882</td>\n",
       "      <td>-1.335526</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>-1.075278</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.297476</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.810666</td>\n",
       "      <td>-0.013474</td>\n",
       "      <td>-0.672699</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.723092</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-1.654549</td>\n",
       "      <td>-1.839275</td>\n",
       "      <td>-0.668103</td>\n",
       "      <td>-0.368769</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.189302</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-0.159552</td>\n",
       "      <td>-0.202559</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-0.107566</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>-1.767431</td>\n",
       "      <td>0.791699</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>-0.811933</td>\n",
       "      <td>-1.088528</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAD      LOAN   MORTDUE     VALUE       YOJ     CLAGE      NINQ  \\\n",
       "index                                                                      \n",
       "0       True -1.832283 -1.295882 -1.335526  0.266788 -1.075278 -0.065054   \n",
       "1       True -1.810666 -0.013474 -0.672699 -0.236615 -0.723092 -0.826792   \n",
       "2       True -1.789048 -1.654549 -1.839275 -0.668103 -0.368769 -0.065054   \n",
       "3       True -1.789048 -0.159552 -0.202559 -0.236615 -0.061033 -0.065054   \n",
       "4      False -1.767431  0.791699  0.311107 -0.811933 -1.088528 -0.826792   \n",
       "\n",
       "           CLNO   DEBTINC  DEROGzero  REASON_HomeImp  REASON_IsMissing  \\\n",
       "index                                                                    \n",
       "0     -1.297476  0.137456       True               1                 0   \n",
       "1     -0.756608  0.137456       True               1                 0   \n",
       "2     -1.189302  0.137456       True               1                 0   \n",
       "3     -0.107566  0.137456       True               0                 1   \n",
       "4     -0.756608  0.137456       True               1                 0   \n",
       "\n",
       "       JOB_Office  JOB_Other  JOB_ProfExe  JOB_Sales  JOB_Self  DELINQcat_1  \\\n",
       "index                                                                         \n",
       "0               0          1            0          0         0            0   \n",
       "1               0          1            0          0         0            0   \n",
       "2               0          1            0          0         0            0   \n",
       "3               0          1            0          0         0            0   \n",
       "4               1          0            0          0         0            0   \n",
       "\n",
       "       DELINQcat_1+  \n",
       "index                \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "      <th>DEROGzero</th>\n",
       "      <th>REASON_HomeImp</th>\n",
       "      <th>REASON_IsMissing</th>\n",
       "      <th>JOB_Office</th>\n",
       "      <th>JOB_Other</th>\n",
       "      <th>JOB_ProfExe</th>\n",
       "      <th>JOB_Sales</th>\n",
       "      <th>JOB_Self</th>\n",
       "      <th>DELINQcat_1</th>\n",
       "      <th>DELINQcat_1+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.832283</td>\n",
       "      <td>-1.295882</td>\n",
       "      <td>-1.335526</td>\n",
       "      <td>0.266788</td>\n",
       "      <td>-1.075278</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.297476</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.810666</td>\n",
       "      <td>-0.013474</td>\n",
       "      <td>-0.672699</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.723092</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-1.654549</td>\n",
       "      <td>-1.839275</td>\n",
       "      <td>-0.668103</td>\n",
       "      <td>-0.368769</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-1.189302</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.789048</td>\n",
       "      <td>-0.159552</td>\n",
       "      <td>-0.202559</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.061033</td>\n",
       "      <td>-0.065054</td>\n",
       "      <td>-0.107566</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.767431</td>\n",
       "      <td>0.791699</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>-0.811933</td>\n",
       "      <td>-1.088528</td>\n",
       "      <td>-0.826792</td>\n",
       "      <td>-0.756608</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LOAN   MORTDUE     VALUE       YOJ     CLAGE      NINQ      CLNO  \\\n",
       "index                                                                         \n",
       "0     -1.832283 -1.295882 -1.335526  0.266788 -1.075278 -0.065054 -1.297476   \n",
       "1     -1.810666 -0.013474 -0.672699 -0.236615 -0.723092 -0.826792 -0.756608   \n",
       "2     -1.789048 -1.654549 -1.839275 -0.668103 -0.368769 -0.065054 -1.189302   \n",
       "3     -1.789048 -0.159552 -0.202559 -0.236615 -0.061033 -0.065054 -0.107566   \n",
       "4     -1.767431  0.791699  0.311107 -0.811933 -1.088528 -0.826792 -0.756608   \n",
       "\n",
       "        DEBTINC  DEROGzero  REASON_HomeImp  REASON_IsMissing  JOB_Office  \\\n",
       "index                                                                      \n",
       "0      0.137456       True               1                 0           0   \n",
       "1      0.137456       True               1                 0           0   \n",
       "2      0.137456       True               1                 0           0   \n",
       "3      0.137456       True               0                 1           0   \n",
       "4      0.137456       True               1                 0           1   \n",
       "\n",
       "       JOB_Other  JOB_ProfExe  JOB_Sales  JOB_Self  DELINQcat_1  DELINQcat_1+  \n",
       "index                                                                          \n",
       "0              1            0          0         0            0             0  \n",
       "1              1            0          0         0            0             1  \n",
       "2              1            0          0         0            0             0  \n",
       "3              1            0          0         0            0             0  \n",
       "4              0            0          0         0            0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['BAD'], axis=1) #code the variables in the most standard way for your usage\n",
    "y = df[['BAD']]\n",
    "\n",
    "X.head() #inspect that variables were correctly separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BAD\n",
       "index       \n",
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4      False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> (5960, 18) (5960, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(X), type(y), X.shape, y.shape) # double check that types and dimensions are correct before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for the Tree\n",
    "\n",
    "Decision trees work by recursively partitioning data which means:\n",
    "\n",
    "Many potential ways to split the data are calculated (eg. we are going to go through all unique values of each column and finding the midpoint between sequential values). For each potential split, we evaluate whether the target variable has more homogeneity in each leaf. This is done by calculating 'impurity' of the parent node and comparing it with the sum of the impurity of the child nodes. There are three major impurity functions: entropy, gini and misclassification. We will be using entropy in our example. The split which yields the lowest impurity is chosen and the process is repeated for the new nodes (this is recursion). \n",
    "\n",
    "The method of choosing the split which yields the lowest impurity is called the greedy search method. The following functions will help the decision tree implement greedy search tactics on the data. The algorithm stops either when purity in each node is reached or when it has reached a maximum depth (max amount of recursions we allow) specified in our function.\n",
    "\n",
    "Many functions for the tree are not found in Python packages and it is cleaner to write them out first then put them together in our main algorithm. Each function below does a specific action which will be used in our final tree function at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(y):\n",
    "    \n",
    "    'checks if a leaf node is perfectly pure, in other words, if the leaf node contains only one class'\n",
    "    \n",
    "    unique_classes = np.unique(y) #count number of classes in section of data\n",
    "\n",
    "    if len(unique_classes) == 1: #check if the node is pure\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(y):\n",
    "    \n",
    "    'classifies data according to the majority class of each leaf'\n",
    "    \n",
    "    unique_classes, counts_unique_classes = np.unique(y, return_counts=True)\n",
    "    #returns classes and no. of obs per class\n",
    "\n",
    "    index = counts_unique_classes.argmax() #index of class with most obs\n",
    "    classification = unique_classes[index] #class chosen for classification which is class with most obs\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(X):\n",
    "    \n",
    "    'first, takes every unique value of every feature in the feature space, then finds the midpoint between each value'\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = X.shape #don't need rows, we choose the column to split on\n",
    "    # only need second value of .shape which is columns\n",
    "    \n",
    "    for column_index in range(n_columns):\n",
    "        potential_splits[column_index] = [] \n",
    "        values = X[:, column_index] \n",
    "        unique_values = np.unique(values) #get all unique values in each column\n",
    "\n",
    "        for index in range(len(unique_values)): #all unique feature values\n",
    "            if index != 0: #skip first value, we need the difference between next values\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1] #find a value and the next smallest value\n",
    "                potential_split = (current_value + previous_value) / 2 #find difference between the two as a potential split\n",
    "                \n",
    "                #consider all values which lie between two values as a potential split\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, split_column, split_value):\n",
    "    \n",
    "    'splits data based on specific value, will yield both a split for the features X and target y'\n",
    "    \n",
    "    split_column_values = X[:, split_column]\n",
    "\n",
    "    X_below = X[split_column_values <= split_value] #partitions data according to split values from previous functions\n",
    "    X_above = X[split_column_values >  split_value]\n",
    "    \n",
    "    y_below = y[split_column_values <= split_value]\n",
    "    y_above = y[split_column_values >  split_value]\n",
    "    \n",
    "    return X_below, X_above, y_below, y_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    \n",
    "    'calculates entropy for each partition of data'\n",
    "    \n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum() #probability of each class\n",
    "    entropy = sum(probabilities * -np.log2(probabilities)) #could replace with Gini impurity or misclassification\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(y_below, y_above): \n",
    "    \n",
    "    'calculates the total entropy after each split'\n",
    "       \n",
    "    n = len(y_below) + len(y_above)\n",
    "    p_data_below = len(y_below) / n\n",
    "    p_data_above = len(y_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(y_below)\n",
    "                      + p_data_above * calculate_entropy(y_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(X, y, potential_splits):\n",
    "    \n",
    "    'selects which split lowered entropy the most'\n",
    "    \n",
    "    overall_entropy = 9999 #set arbitrarily high, the function will loop over and replace this with lower impurity values\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            X_below, X_above, y_below, y_above = split_data(X, y, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(y_below, y_above)\n",
    "            \n",
    "            #goes through each potential split and only updates if it lowers entropy\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy: \n",
    "                overall_entropy = current_overall_entropy #updates only if lower entropy split found, in the ned this is greedy search\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Algorithm\n",
    "\n",
    "The tree will now implement the helper functions and display the decision which yielded the best split if printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(X, y, counter=0, min_samples=2, max_depth=5): \n",
    "    \n",
    "    # data preparation\n",
    "    if counter == 0: # counter tells us how deep the tree is, this is before the tree is initiated\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = X.columns\n",
    "        X = X.values #change all to NumPy array for faster calculations\n",
    "        y = y.values\n",
    "    else:\n",
    "        data = X #if we have started the tree, X should already be a NumPy array from the code above \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(y)) or (len(X) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(y)\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1 #tells us how deep the tree is\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(X) #check for all possible splits\n",
    "        best_split_column, best_split_value = determine_best_split(X, y, potential_splits) #select best split based on entropy\n",
    "        X_below, X_above, y_below, y_above = split_data(X, y, best_split_column, best_split_value) #execute best split\n",
    "        \n",
    "        # code to explain decisions made by tree to users\n",
    "        feature_name = COLUMN_HEADERS[best_split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, best_split_value) #initiate explanation of split\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # pull answers from tree\n",
    "        yes_answer = decision_tree_algorithm(X_below, y_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(X_above, y_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        # ensure explanation actually shows useful information\n",
    "        if yes_answer == no_answer: #if decisions are the same, only display one\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grow First Tree\n",
    "\n",
    "Test the tree and display the decisions with a shallow depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(X, y, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEBTINC <= 0.13253751764464605': [False,\n",
      "                                    {'DEBTINC <= 0.137471043429223': [True,\n",
      "                                                                      False]}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAD                      True\n",
       "LOAN                 -1.78905\n",
       "MORTDUE              -1.65455\n",
       "VALUE                -1.83928\n",
       "YOJ                 -0.668103\n",
       "CLAGE               -0.368769\n",
       "NINQ               -0.0650545\n",
       "CLNO                  -1.1893\n",
       "DEBTINC              0.137456\n",
       "DEROGzero                True\n",
       "REASON_HomeImp              1\n",
       "REASON_IsMissing            0\n",
       "JOB_Office                  0\n",
       "JOB_Other                   1\n",
       "JOB_ProfExe                 0\n",
       "JOB_Sales                   0\n",
       "JOB_Self                    0\n",
       "DELINQcat_1                 0\n",
       "DELINQcat_1+                0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's take an example and see how the tree classifies it\n",
    "\n",
    "example = df.iloc[2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0] #checks what is the next data split\n",
    "    feature_name, comparison_operator, value = question.split() #splits question into elements\n",
    "\n",
    "    # ask question\n",
    "    if example[feature_name] <= float(value): # checks key element for split\n",
    "        answer = tree[question][0] # selects yes answer\n",
    "    else:\n",
    "        answer = tree[question][1] # selects no answer\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict): # if answer is not a dictionary, we have reached a decision\n",
    "        return answer # display prediction\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer # continue if another dictionary is reached\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAD    True\n",
       "Name: 2, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification for this one instance above is correct, how well does this tree do for the rest of the data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(X.apply(classify_example, axis=1, args=(tree,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851006711409396"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.mean(np.array(pred) == np.array(y))\n",
    "\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is able to classify a good proportion of the test set well even with only a depth of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher Depth in Tree\n",
    "\n",
    "Test the tree and display the decisions with a higher depth to see if accuracy changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_deep = decision_tree_algorithm(X, y, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_deep = pd.DataFrame(X.apply(classify_example, axis=1, args=(tree_deep,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8897651006711409"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_deep = np.mean(np.array(pred_deep) == np.array(y))\n",
    "\n",
    "error_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the tree is even better with this depth. However, as we continue to increase depth, there will come a point where the accuracy decreases as the tree internalizes noise from the data. This is called overfitting and weakens the tree's ability to classify unseen observations. Thus, the tree can be deepened only until the test set accuracy begins decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees with Sci-Kit Learn\n",
    "\n",
    "As mentioned, the package Ski-Kit Learn has prebuilt functions which avoid coding most algorithms by scratch. Now armed with the knowledge of the inner workings of the decision tree, it should be easier to understand what this algorithm is trying to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=2, max_depth=2) #keep tree at a low depth\n",
    "\n",
    "dt_shallow = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_shallow = dt_shallow.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dt_shallow[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851006711409396"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_correct_shallow = pred_dt_shallow == y.iloc[:,0]\n",
    "accuracy_shallow = classify_correct_shallow.mean()\n",
    "\n",
    "\n",
    "accuracy_shallow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(251.5,313.833,'X[7] <= 0.133\\nentropy = 0.721\\nsamples = 5960\\nvalue = [4771, 1189]'),\n",
       " Text(125.75,188.3,'X[17] <= 0.5\\nentropy = 0.315\\nsamples = 2341\\nvalue = [2208, 133]'),\n",
       " Text(62.875,62.7667,'entropy = 0.261\\nsamples = 2215\\nvalue = [2117, 98]'),\n",
       " Text(188.625,62.7667,'entropy = 0.852\\nsamples = 126\\nvalue = [91, 35]'),\n",
       " Text(377.25,188.3,'X[7] <= 0.137\\nentropy = 0.871\\nsamples = 3619\\nvalue = [2563, 1056]'),\n",
       " Text(314.375,62.7667,'entropy = 0.959\\nsamples = 1273\\nvalue = [486, 787]'),\n",
       " Text(440.125,62.7667,'entropy = 0.514\\nsamples = 2346\\nvalue = [2077, 269]')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.plot_tree(dt_shallow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SK Learn Tree with No Limit on Depth\n",
    "\n",
    "If we remove the maximum depth parameter, the algorithm will go as far as it can until all nodes are pure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=2)\n",
    "\n",
    "dt_deep = clf.fit(X, y)\n",
    "\n",
    "pred_dt_deep = dt_deep.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dt_deep[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_correct_deep = pred_dt_deep == y.iloc[:,0]\n",
    "accuracy_deep = classify_correct_deep.mean()\n",
    "\n",
    "accuracy_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this seems great at first glance, what is the problem here? What does this mean for new data that we encounter whose idiosyncracies may be slightly different than the data we used to train the model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
