{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Now that we introduced Pandas, students you apply k-means from tutorial 2 to the HMEQ data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using inbuilt functions from R Homework 1\n",
    "The density of the normal distribution with expected value $\\mu$ and variance $\\sigma$ is given as\n",
    "$$f(x | \\mu ,\\sigma ^{2}) = {\\frac {1}{\\sqrt {2\\sigma ^{2}\\pi}}}e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a nice plot of the bell shape that is so famous. We already made sure that some libraries that we will need are imported. First, define two variables that store the two parameters of the normal distribution; no need to spill out these parameters, right?. Next generate some values $x$. Say you want to plot the bell curve for $x \\in \\{-3, 3\\} $. Use the NumPy function `linespace()` for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for each value of $x$, compute the probability that a normally distributed random variable would be arbitrarily close to that value. To calculate the probability density of the normal distribution, you can use the function `norm.pdf`, which is part of the stats models library, which we import below. So you can write something like ` stats.norm.pdf(...)` where ... stands for the arguments that the function requires. Make sure to store the results of the computation in a variable **nvValues**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to plot. Create a simple graph of **nvValues** against **x** `plot()`function. Let's say you want your line to be in red color. Use the help and web search to find out how to plot a red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borrow from R Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model assessment\n",
    "- produce prob predictions, vary threshold, and investigate who accuracy varies\n",
    "- manual ROC\n",
    "- we criticized accuracy for being dependent on the cut-off. Say you want to use accuracy, for example, because your manager ask you to produce an accuracy figure. To do better than using the default cut-off 0.5, you decide to use a cut-off such that the fraction of bad:good in the test data equates to that ration for the training:data. Implement this approach and calc accuracy \n",
    "\n",
    "\n",
    "# Regularization and model selection\n",
    "- implement logit from scratch with L2 regularization (https://towardsdatascience.com/implement-logistic-regression-with-l2-regularization-from-scratch-in-python-20bd4ee88a59)\n",
    "- we showcase tuning in sklearn with one test set. Implement nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (adams)",
   "language": "python",
   "name": "pycharm-feb95198"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
